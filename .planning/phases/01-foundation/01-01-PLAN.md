---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .claude/agents/verifier.md
  - .claude/instructions/verifier/instructions.md
  - .claude/instructions/verifier/error-types.md
  - .claude/instructions/verifier/metrics.md
autonomous: true

must_haves:
  truths:
    - "Agent definitions are thin wrappers (<50 lines) that reference external instruction files"
    - "Instructions are stored in .claude/instructions/ and can be edited without touching agent definitions"
    - "Verifier agent reads instruction files at runtime using progressive disclosure"
  artifacts:
    - path: ".claude/agents/verifier.md"
      provides: "Verifier agent definition with file references"
      contains: ".claude/instructions/verifier/"
    - path: ".claude/instructions/verifier/instructions.md"
      provides: "Main verifier behavior instructions"
      min_lines: 50
    - path: ".claude/instructions/verifier/error-types.md"
      provides: "Error categorization taxonomy"
      contains: ["omission", "hallucination", "format_error", "wrong_value"]
    - path: ".claude/instructions/verifier/metrics.md"
      provides: "Metric computation guide"
      contains: ["precision", "recall", "F1"]
  key_links:
    - from: ".claude/agents/verifier.md"
      to: ".claude/instructions/verifier/instructions.md"
      via: "file reference in workflow section"
      pattern: "@.claude/instructions/verifier/"
---

<objective>
Create the dynamic agent architecture where agent definitions are thin wrappers that load instructions from external files.

Purpose: Enable the self-improvement loop (Phase 5-6) to modify agent behavior by editing instruction files without touching agent definitions. This separation is foundational to the entire improvement system.

Output: Verifier agent definition + instruction files in .claude/instructions/verifier/
</objective>

<execution_context>
@/Users/Andrew/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Andrew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation/01-RESEARCH.md

Research shows Claude Code supports dynamic instruction loading through progressive disclosure - agents reference external files that Claude loads on-demand. This is the recommended pattern from official Anthropic documentation.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create verifier agent definition</name>
  <files>.claude/agents/verifier.md</files>
  <action>
Create the verifier agent definition as a thin wrapper that:

1. Has frontmatter with:
   - name: verifier
   - description: Compares extracted JSON against ground truth CSV and computes precision/recall/F1 metrics
   - tools: Read, Write, Bash

2. Has a <role> section that:
   - Describes the verifier's purpose in 2-3 sentences
   - Lists the instruction files it should read:
     - .claude/instructions/verifier/instructions.md (main workflow)
     - .claude/instructions/verifier/error-types.md (error categorization)
     - .claude/instructions/verifier/metrics.md (metric formulas)
   - Instructs the agent to read these files before starting work

3. Has a <workflow> section that:
   - Outlines the high-level steps (read instructions, load data, compare, compute metrics, generate report)
   - Does NOT contain detailed implementation (that goes in instruction files)

Keep the agent definition under 50 lines. All behavioral details go in instruction files.

Create the directory structure first:
```bash
mkdir -p .claude/agents
mkdir -p .claude/instructions/verifier
```
  </action>
  <verify>
- File exists at .claude/agents/verifier.md
- File is under 50 lines
- File contains references to .claude/instructions/verifier/
- File has valid frontmatter with name, description, tools
  </verify>
  <done>Verifier agent definition exists and references external instruction files</done>
</task>

<task type="auto">
  <name>Task 2: Create verifier instruction files</name>
  <files>
.claude/instructions/verifier/instructions.md
.claude/instructions/verifier/error-types.md
.claude/instructions/verifier/metrics.md
  </files>
  <action>
Create three instruction files in .claude/instructions/verifier/:

**instructions.md** - Main verifier workflow:
- Version header (v1.0.0) for tracking changes
- Purpose section explaining what the verifier does
- Input/output specification (ground_truth.csv + extracted.json -> metrics + report)
- Field comparison process:
  1. Load ground truth CSV using pandas
  2. Load extracted JSON
  3. Map CSV columns to JSON field paths (reference field_mapping.yaml when created)
  4. Compare each field using appropriate comparison logic
  5. Categorize errors (reference error-types.md)
  6. Compute metrics (reference metrics.md)
  7. Generate HTML report
- Numeric comparison rules: tolerance of ±0.5% OR ±0.01 (whichever is larger)
- String comparison rules: case-insensitive, trim whitespace
- Boolean comparison: exact match
- Note: Detailed metric formulas are in metrics.md

**error-types.md** - Error categorization taxonomy:
- Define the four error types with examples:
  - omission: Expected field missing from extraction
  - hallucination: Field present in extraction but not in ground truth
  - format_error: Field present but wrong type/format
  - wrong_value: Field present, correct type, but incorrect value
- Include examples for each type using building extraction context
- Note how each error type informs improvement strategy

**metrics.md** - Metric computation guide:
- Explain field-level (not document-level) computation
- Define terms: True Positive, False Positive, False Negative
- Provide formulas:
  - Precision = TP / (TP + FP)
  - Recall = TP / (TP + FN)
  - F1 = 2 * (P * R) / (P + R)
- Explain how to compute aggregate metrics across all 5 evals (macro-F1)
- Handle edge cases: division by zero -> return 0
  </action>
  <verify>
- All three files exist in .claude/instructions/verifier/
- instructions.md is at least 50 lines with workflow details
- error-types.md defines all four error categories
- metrics.md has precision/recall/F1 formulas
  </verify>
  <done>All instruction files created with complete behavioral specifications</done>
</task>

</tasks>

<verification>
Run these checks to verify the agent architecture is correctly set up:

```bash
# Verify agent definition exists and is thin
wc -l .claude/agents/verifier.md  # Should be < 50 lines

# Verify instruction references
grep -c "instructions/verifier" .claude/agents/verifier.md  # Should be >= 3

# Verify instruction files exist
ls -la .claude/instructions/verifier/

# Verify error types are defined
grep -E "omission|hallucination|format_error|wrong_value" .claude/instructions/verifier/error-types.md | wc -l  # Should be >= 4

# Verify metrics are defined
grep -E "precision|recall|F1" .claude/instructions/verifier/metrics.md | wc -l  # Should be >= 3
```
</verification>

<success_criteria>
1. .claude/agents/verifier.md exists and is under 50 lines
2. Agent definition references all three instruction files in .claude/instructions/verifier/
3. instructions.md contains complete field comparison workflow
4. error-types.md defines omission, hallucination, format_error, wrong_value
5. metrics.md contains precision/recall/F1 formulas with field-level computation
6. All instruction files can be edited independently without touching agent definition
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md`
</output>
