---
phase: 07-cv-sensors
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - src/agents/orchestrator.py
  - .claude/instructions/orientation-extractor/pass1-north-arrow.md
  - .claude/instructions/orientation-extractor/pass2-elevation-matching.md
  - test_orientation_twopass.py
autonomous: true

must_haves:
  truths:
    - "Orchestrator runs CV sensors before orientation passes and injects structured hints into prompts"
    - "Pass 1 instructions tell the LLM to use CV-measured north arrow angle instead of visual estimation"
    - "Pass 2 instructions tell the LLM to use CV-measured wall edge angles instead of visual estimation"
    - "Two-pass orientation test runner works unchanged (CV hints injected transparently by orchestrator)"
  artifacts:
    - path: "src/agents/orchestrator.py"
      provides: "CV sensor integration in orientation pipeline"
      contains: "cv_hints"
    - path: ".claude/instructions/orientation-extractor/pass1-north-arrow.md"
      provides: "Updated Pass 1 instructions referencing CV hints"
      contains: "CV_HINTS"
    - path: ".claude/instructions/orientation-extractor/pass2-elevation-matching.md"
      provides: "Updated Pass 2 instructions referencing CV hints"
      contains: "CV_HINTS"
  key_links:
    - from: "src/agents/orchestrator.py"
      to: "src/cv_sensors"
      via: "import and call detect_north_arrow_angle, measure_wall_edge_angles"
      pattern: "from cv_sensors.*import"
    - from: "src/agents/orchestrator.py"
      to: "orientation pass prompts"
      via: "cv_hints dict formatted as JSON and injected into prompt string"
      pattern: "cv_hints.*json"
    - from: "pass1-north-arrow.md"
      to: "CV_HINTS section in prompt"
      via: "LLM reads CV hints from prompt before angle estimation"
      pattern: "CV_HINTS"
---

<objective>
Wire CV sensor outputs into the orientation extraction pipeline so LLM passes receive deterministic angle measurements as structured hints.

Purpose: The LLM currently estimates angles visually, producing noisy results (68-110 degree range for the same drawing). By providing CV-measured angles upfront, the LLM can focus on semantic reasoning (which is the entry? what building type?) while relying on precise measurements for the geometric part.

Output: Modified orchestrator that runs CV sensors before orientation passes, updated instruction files that reference CV hints, and validated end-to-end orientation extraction.
</objective>

<execution_context>
@/Users/Andrew/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Andrew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-cv-sensors/07-RESEARCH.md
@.planning/phases/07-cv-sensors/07-01-SUMMARY.md

Key files to modify:
- `src/agents/orchestrator.py` — `run_orientation_pass_async()`, `run_orientation_twopass_async()`, `build_pdf_read_instructions()`
- `.claude/instructions/orientation-extractor/pass1-north-arrow.md` — Step 1 (north arrow) and Step 3 (drawing angle)
- `.claude/instructions/orientation-extractor/pass2-elevation-matching.md` — Step 2 (wall edge measurement) and Step 3 (north arrow)
- `test_orientation_twopass.py` — may need minor changes to pass CV hints through

Important architectural context:
- The orchestrator invokes agents via subprocess: `claude --agent orientation-extractor --print "<prompt>"`
- CV sensors MUST run in the orchestrator (Python) BEFORE the subprocess call
- CV hints are injected as text in the prompt string — the Claude agent reads them as part of the prompt
- The agent also reads instruction files (.md) via its Read tool at runtime
- CV hints in the prompt + references in instruction files = LLM knows to use measured angles

Integration approach from research (Pattern 5: Hybrid CV + LLM):
- CV sensors produce a `cv_hints` dict with measured angles
- This dict is serialized as JSON and embedded in the prompt
- Instructions tell the LLM: "If CV_HINTS are provided, use the measured angles. Only fall back to visual estimation if CV confidence is 'none'."
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate CV sensors into orchestrator orientation pipeline</name>
  <files>src/agents/orchestrator.py</files>
  <action>
Modify `src/agents/orchestrator.py` to run CV sensors and inject hints into orientation pass prompts.

1. Add import at top of file (after existing imports):
   ```python
   from cv_sensors import detect_north_arrow_angle, measure_wall_edge_angles
   from cv_sensors.wall_detection import estimate_building_rotation
   ```

2. Add new function `run_cv_sensors(eval_dir: Path, document_map: DocumentMap) -> dict`:
   - Find site plan page(s) from document_map: use `get_relevant_pages_for_domain("orientation", document_map)` to get pages, then filter for site plan pages using `document_map.site_plan_pages`
   - If no site plan pages, use first drawing page
   - For the best candidate site plan page, determine the PDF path and local page number (same logic as `build_pdf_read_instructions` — look up `page_info.pdf_name` and `page_info.pdf_page_number`)
   - Run `detect_north_arrow_angle(pdf_path, local_page_num)` — catch exceptions, return `{"confidence": "none"}` on failure
   - Run `measure_wall_edge_angles(pdf_path, local_page_num)` — catch exceptions, return empty list on failure
   - Run `estimate_building_rotation(pdf_path, local_page_num)` — catch exceptions, return `{"confidence": "none"}` on failure
   - Return structured dict:
     ```python
     {
         "north_arrow": {
             "angle": float_or_none,
             "confidence": str,
             "method": str,
         },
         "wall_edges": [
             {"angle_from_horizontal": float, "length": float, "position": str, "perpendicular_angle": float},
             ...
         ],
         "building_rotation": {
             "rotation_from_horizontal": float_or_none,
             "confidence": str,
         },
         "site_plan_page": int,
     }
     ```
   - Log CV sensor results at INFO level

3. Modify `run_orientation_pass_async()` to accept an optional `cv_hints: Optional[Dict] = None` parameter:
   - If cv_hints is provided, format them as a JSON block and inject into the prompt BEFORE the instruction file reference
   - Format:
     ```
     CV SENSOR MEASUREMENTS (deterministic, from computer vision):
     {json.dumps(cv_hints, indent=2)}

     These measurements are precise and repeatable. Use them as described in your instructions.
     ```

4. Modify `run_orientation_twopass_async()` to:
   - Call `run_cv_sensors(eval_dir, document_map)` BEFORE running orientation passes
   - Pass the resulting `cv_hints` dict to both `run_orientation_pass_async()` calls
   - Include cv_hints in the returned dict for downstream tracking
   - If CV sensors fail entirely (exception), proceed without hints (graceful degradation)

5. Also modify the synchronous `run_orientation_extraction()` to include CV hints (same pattern — call `run_cv_sensors`, inject into prompt).

6. Modify the test runner integration: The `run_pass()` function in `test_orientation_twopass.py` is a standalone implementation. Update `run_orientation_pass_async` in orchestrator so the test runner can also benefit. The cleanest approach: make `run_cv_sensors` a standalone function that `test_orientation_twopass.py` can also import and call.

IMPORTANT constraints:
- Do NOT change the prompt structure in a way that breaks backwards compatibility if CV sensors aren't available
- CV hints should be an OPTIONAL section — if cv_hints is None or empty, the prompt should work exactly as before
- Do NOT change the verification logic in `verify_orientation_passes()` — that stays the same
- Keep the function signatures backwards-compatible (new params are Optional with None defaults)
  </action>
  <verify>
Run: `cd /Users/Andrew/Projects/takeoff2 && python3 -c "
import sys; sys.path.insert(0, 'src')
from agents.orchestrator import run_cv_sensors, get_relevant_pages_for_domain, discover_source_pdfs
from schemas.discovery import DocumentMap
from pathlib import Path
import json

eval_dir = Path('evals/canterbury-rd')
source_pdfs = discover_source_pdfs(eval_dir)

# Load cached discovery
with open('evals/.cache/canterbury-rd_discovery.json') as f:
    doc_map = DocumentMap.model_validate(json.load(f))

hints = run_cv_sensors(eval_dir, doc_map)
print(json.dumps(hints, indent=2))
"`
Verify: CV hints dict is returned with north_arrow angle, wall_edges list, and building_rotation. No errors.
  </verify>
  <done>
    - `run_cv_sensors()` function exists in orchestrator and returns structured hints
    - `run_orientation_pass_async()` accepts and injects cv_hints into prompts
    - `run_orientation_twopass_async()` calls CV sensors first, passes hints to both passes
    - CV hints injection is optional — pipeline works with or without hints
    - Backwards compatibility maintained
  </done>
</task>

<task type="auto">
  <name>Task 2: Update orientation instruction files to use CV hints</name>
  <files>.claude/instructions/orientation-extractor/pass1-north-arrow.md, .claude/instructions/orientation-extractor/pass2-elevation-matching.md</files>
  <action>
Update both instruction files to reference and prioritize CV sensor measurements when available.

1. Update `pass1-north-arrow.md`:

   In Step 1 (Find North Arrow), add a new subsection at the TOP:
   ```
   ### Using CV Hints (if provided)

   If the prompt includes a "CV SENSOR MEASUREMENTS" section:
   - **North arrow angle:** Use `north_arrow.angle` directly as the north arrow angle. Do NOT re-estimate visually.
     Only fall back to visual estimation if `north_arrow.confidence` is "none" (meaning CV could not detect the arrow).
   - **Building rotation:** The `building_rotation.rotation_from_horizontal` tells you how the building sits on the page.
     This can help you estimate the drawing_angle more precisely.
   - Record the CV values in your output JSON.
   ```

   In Step 3 (Measure Front Drawing Angle), add:
   ```
   ### Using CV Wall Edge Hints

   If CV wall edges are provided, use them to determine the drawing_angle precisely:
   - Find the wall edge that best matches the front/entry wall based on your Step 2 analysis
   - The `perpendicular_angle` of that wall edge IS the drawing_angle
   - This is more precise than visual estimation from the page direction table
   ```

   SIMPLIFY the existing visual estimation instructions — add a note that they are FALLBACK when CV hints are not available. The overall instruction file should get slightly shorter or stay the same length despite adding CV hint sections, because the visual estimation steps become fallbacks rather than primary methods.

2. Update `pass2-elevation-matching.md`:

   In Step 2 (Find the Entry Wall on the Site Plan), add at the TOP:
   ```
   ### Using CV Hints (if provided)

   If the prompt includes CV wall edge measurements:
   - The `wall_edges` list contains precisely measured wall angles from the site plan
   - After identifying which wall is the entry wall (using spatial reasoning from Step 1), match it to a CV wall edge:
     - Match by position ("top", "right", "bottom", "left") relative to your entry wall identification
     - Use the matched edge's actual `angle_from_horizontal` for measurement
     - Use the matched edge's `perpendicular_angle` as `entry_drawing_angle`
   - This replaces manual wall edge tracing — CV measurement is more precise
   ```

   In Step 3 (Measure North Arrow), add:
   ```
   ### Using CV Hints

   If CV north arrow angle is provided with confidence != "none", use it directly.
   Do NOT re-estimate the north arrow visually.
   ```

   SIMPLIFY the "Measure the entry direction" subsection in Step 2 — the manual wall tracing instructions become fallback. Add clear labels: "If CV hints available:" vs "Fallback (no CV hints):"

3. KEY DESIGN PRINCIPLE: The LLM still does ALL semantic reasoning:
   - Which elevation shows the entry? (LLM)
   - Is this an ADU or single-family? (LLM)
   - Which wall on the site plan is the entry wall? (LLM)
   - What direction does it face? (LLM chooses from CV wall_edges, or uses CV building_rotation)
   - What is the north arrow angle? (CV provides, LLM accepts or falls back)
   - Final calculation? (LLM, using CV-provided numbers)

   The instructions should make this division of labor clear.
  </action>
  <verify>
Run: `cd /Users/Andrew/Projects/takeoff2 && wc -l .claude/instructions/orientation-extractor/pass1-north-arrow.md .claude/instructions/orientation-extractor/pass2-elevation-matching.md`
Verify: Both files are updated. Line counts should be comparable to originals (90 and 118 lines) — may grow slightly but should not exceed 130 lines each (instructions should simplify as CV takes over measurement burden).

Also verify: `grep -c "CV" .claude/instructions/orientation-extractor/pass1-north-arrow.md .claude/instructions/orientation-extractor/pass2-elevation-matching.md`
Verify: Both files contain CV references (multiple occurrences).
  </verify>
  <done>
    - Pass 1 instructions reference CV north arrow angle and wall edges
    - Pass 2 instructions reference CV wall edges for entry wall measurement
    - Both files clearly separate "with CV hints" (primary) from "fallback" (no CV hints)
    - Semantic reasoning remains with LLM; only geometric measurement delegated to CV
    - Instructions are same length or shorter than originals (measurement steps simplified)
  </done>
</task>

<task type="auto">
  <name>Task 3: Update test runner and run orientation evaluation</name>
  <files>test_orientation_twopass.py</files>
  <action>
Update the test runner to use CV hints, then run a single orientation eval to validate end-to-end.

1. Update `test_orientation_twopass.py`:
   - Import `run_cv_sensors` from `agents.orchestrator` (add to existing imports)
   - Modify `run_pass()` function to:
     a. Accept optional `cv_hints: Optional[Dict] = None` parameter
     b. If cv_hints provided, inject them into the prompt (same format as orchestrator):
        ```
        CV SENSOR MEASUREMENTS (deterministic, from computer vision):
        {json.dumps(cv_hints, indent=2)}

        These measurements are precise and repeatable. Use them as described in your instructions.
        ```
   - Modify `run_twopass_extraction()` to:
     a. Call `run_cv_sensors(eval_dir, document_map)` before running passes
     b. Pass cv_hints to both `run_pass()` calls
     c. Include cv_hints in the returned result dict
   - Add `--no-cv` flag to argparse that skips CV sensor injection (for A/B comparison)

2. Run a SINGLE eval to validate end-to-end:
   `python3 test_orientation_twopass.py --eval canterbury-rd`

   This validates:
   - CV sensors run successfully on real PDF
   - Hints are injected into prompts
   - LLM receives and uses CV hints
   - Final orientation is computed correctly
   - No regressions (canterbury-rd should still pass at 90%)

3. Print CV hint values alongside orientation results in the output table.

NOTE: Do NOT run --all yet (that's expensive and should be done manually by the user). Just validate on one eval that the pipeline works end-to-end.
  </action>
  <verify>
Run: `cd /Users/Andrew/Projects/takeoff2 && python3 test_orientation_twopass.py --eval canterbury-rd`
Verify:
- CV sensor measurements appear in log output
- Two-pass extraction completes successfully
- Final orientation is reported (should be near 90 for canterbury-rd)
- No errors or exceptions
  </verify>
  <done>
    - test_orientation_twopass.py updated to inject CV hints into orientation passes
    - --no-cv flag available for A/B comparison
    - Single eval (canterbury-rd) completes end-to-end with CV hints
    - CV hint values visible in output
    - Pipeline works transparently — same test runner, same output format, better measurements
  </done>
</task>

</tasks>

<verification>
1. `run_cv_sensors()` returns valid hint dict on at least one eval
2. Orientation pass prompts include CV sensor measurements block when hints are available
3. Instruction files reference CV hints and simplify visual estimation to fallback
4. `python3 test_orientation_twopass.py --eval canterbury-rd` completes without errors
5. `python3 test_orientation_twopass.py --eval canterbury-rd --no-cv` also works (backwards compatible)
6. CV hints appear in logged output during orientation extraction
</verification>

<success_criteria>
- Orchestrator calls CV sensors before orientation passes automatically
- CV hint injection is transparent — no changes needed to downstream consumers
- Both orientation instruction files updated with CV hint integration
- End-to-end validation passes on at least one eval case
- --no-cv flag enables A/B comparison for measuring CV impact
- No regressions on canterbury-rd (still passes orientation check)
</success_criteria>

<output>
After completion, create `.planning/phases/07-cv-sensors/07-02-SUMMARY.md`
</output>
