---
phase: 06-automated-improvement-loop
plan: 03
type: execute
wave: 3
depends_on: ["06-02"]
files_modified: []
autonomous: false

must_haves:
  truths:
    - "Loop runs at least 2 iterations without crashing"
    - "History file is created and contains iteration records"
    - "Loop stops when a stop condition is met (or manually interrupted)"
    - "history command displays the iterations that ran"
    - "Each iteration produces eval results in the expected iteration directory"
  artifacts: []
  key_links: []
---

<objective>
Verify the automated improvement loop works end-to-end by running it for a few iterations and confirming all components integrate correctly.

Purpose: The loop controller (Plan 01) and CLI (Plan 02) need to be tested against real eval data with actual critic invocations. This is the integration test that proves the automation works before the user relies on it for the 0.90 F1 target.

Output: Confirmed working loop with iteration history, or identified issues to fix.
</objective>

<execution_context>
@/Users/Andrew/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Andrew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-automated-improvement-loop/06-01-SUMMARY.md
@.planning/phases/06-automated-improvement-loop/06-02-SUMMARY.md

Key files:
@src/improvement/loop.py
@src/improvement/cli.py
@src/improvement/history.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Smoke test the loop with 2 iterations</name>
  <files></files>
  <action>
Run the automated improvement loop for exactly 2 iterations to verify integration:

```bash
python3 -m improvement loop --max-iterations 2 --no-commit --target-f1 0.99
```

Use --target-f1 0.99 to prevent early stop on target (we want it to run the full 2 iterations).
Use --no-commit to avoid polluting git history during testing.

If the loop fails:
1. Read the error output
2. Fix the issue in the relevant module (loop.py, history.py, or cli.py)
3. Re-run until 2 iterations complete successfully

After the loop completes, verify:
1. History file exists: `ls evals/../.improvement-history.json` (or `ls .improvement-history.json` from project root)
2. History has entries: `python3 -c "import json; d=json.load(open('.improvement-history.json')); print(f'{len(d[\"iterations\"])} iterations recorded')"`
3. History command works: `python3 -m improvement history`

This task may require debugging and iteration. Common failure modes:
- Import errors (wrong module paths)
- Critic subprocess timeout (increase timeout or handle gracefully)
- Missing eval data (ensure extraction results exist from prior phases)
- JSON serialization issues in history
  </action>
  <verify>
1. Loop completed 2 iterations (or stopped with a valid stop reason)
2. `.improvement-history.json` exists and contains iteration records
3. `python3 -m improvement history` displays a table with the iterations
  </verify>
  <done>Loop ran for 2 iterations, history file was created, and history command displays results.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Automated improvement loop that runs critic -> apply -> extract -> verify cycles with:
    - Configurable stop conditions (target F1, max iterations, plateau detection)
    - JSON-based iteration history with persistence and resume
    - CLI commands: `loop` (run/resume) and `history` (view progress)
    - Integration with all existing improvement infrastructure
  </what-built>
  <how-to-verify>
    1. Review the history output from Task 1: `python3 -m improvement history`
    2. Check if F1 metrics are reasonable (should be near current baseline ~0.815)
    3. Try running the loop again to verify resume works:
       `python3 -m improvement loop --max-iterations 3 --no-commit --target-f1 0.99`
       (should resume from where it left off, not start over)
    4. Optionally run a focused loop:
       `python3 -m improvement loop --max-iterations 2 --focus zones-extractor --no-commit`
    5. Verify all 6 CLI commands still work:
       `python3 -m improvement --help`

    If you want to run the full optimization toward 0.90 F1:
       `python3 -m improvement loop --target-f1 0.90 --patience 5`
  </how-to-verify>
  <resume-signal>Type "approved" to mark Phase 6 complete, or describe any issues found.</resume-signal>
</task>

</tasks>

<verification>
1. Loop ran for at least 2 iterations without crash
2. History file persists across runs
3. All CLI commands (improve, loop, history, apply, rollback, context) work
4. Resume capability confirmed (second run continues from first)
</verification>

<success_criteria>
- Automated loop runs end-to-end against real eval data
- Iteration history tracks metrics and supports resume
- Human verified the output and confirmed readiness for production use
</success_criteria>

<output>
After completion, create `.planning/phases/06-automated-improvement-loop/06-03-SUMMARY.md`
</output>
