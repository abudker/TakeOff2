---
phase: 04-multi-domain-extraction
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - src/agents/orchestrator.py
  - src/schemas/building_spec.py
autonomous: true

must_haves:
  truths:
    - "Orchestrator invokes all 4 domain extractors in parallel using asyncio"
    - "Orchestrator merges results from all extractors into single BuildingSpec"
    - "Conflicts between extractors are flagged in BuildingSpec.conflicts array"
    - "Extraction continues with partial results if one extractor fails"
    - "Extraction status for each domain is tracked in BuildingSpec.extraction_status"
  artifacts:
    - path: "src/agents/orchestrator.py"
      provides: "Parallel extraction orchestration with merge logic"
      contains: "asyncio.gather"
      min_lines: 400
    - path: "src/schemas/building_spec.py"
      provides: "ExtractionConflict and ExtractionStatus models"
      contains: "ExtractionConflict"
  key_links:
    - from: "src/agents/orchestrator.py"
      to: ".claude/agents/zones-extractor.md"
      via: "invoke_claude_agent call"
      pattern: "zones-extractor"
    - from: "src/agents/orchestrator.py"
      to: ".claude/agents/windows-extractor.md"
      via: "invoke_claude_agent call"
      pattern: "windows-extractor"
    - from: "src/agents/orchestrator.py"
      to: ".claude/agents/hvac-extractor.md"
      via: "invoke_claude_agent call"
      pattern: "hvac-extractor"
    - from: "src/agents/orchestrator.py"
      to: ".claude/agents/dhw-extractor.md"
      via: "invoke_claude_agent call"
      pattern: "dhw-extractor"
    - from: "src/agents/orchestrator.py"
      to: "src/schemas/building_spec.py"
      via: "import BuildingSpec"
      pattern: "from schemas.building_spec import"
---

<objective>
Extend orchestrator to invoke all four domain extractors (zones, windows, hvac, dhw) in parallel using asyncio, merge their results into a complete BuildingSpec, and handle conflicts and partial failures gracefully.

Purpose: This is the core of Phase 4 - transitioning from single-domain (project/envelope) extraction to full multi-domain extraction with parallel execution for speed.

Output: Updated orchestrator.py with asyncio-based parallel extraction, merge logic with conflict detection, and updated schema with extraction metadata.
</objective>

<execution_context>
@/Users/Andrew/.claude/get-shit-done/workflows/execute-plan.md
@/Users/Andrew/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-multi-domain-extraction/04-CONTEXT.md
@.planning/phases/04-multi-domain-extraction/04-RESEARCH.md

# Current orchestrator to extend
@src/agents/orchestrator.py

# Schema to extend with conflict/status models
@src/schemas/building_spec.py

# Phase 3 orchestrator patterns
@.planning/phases/03-single-domain-extraction/03-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Extraction Metadata to Schema</name>
  <files>src/schemas/building_spec.py</files>
  <action>
Add extraction metadata models to building_spec.py. These track per-domain status and flag conflicts for human review.

Add these new models BEFORE the BuildingSpec class:

```python
class ExtractionConflict(BaseModel):
    """A conflict between extractor outputs."""
    field: str = Field(description="Field name with conflict")
    item_name: Optional[str] = Field(default=None, description="Array item name if applicable")
    source_extractor: str = Field(description="First extractor that reported value")
    reported_value: Any = Field(description="Value from first extractor")
    conflicting_extractor: str = Field(description="Second extractor with different value")
    conflicting_value: Any = Field(description="Value from second extractor")
    resolution: str = Field(default="flagged_for_review", description="Resolution status")

class ExtractionStatus(BaseModel):
    """Per-domain extraction status."""
    domain: str = Field(description="Domain name: project, zones, windows, hvac, dhw")
    status: str = Field(description="success, partial, failed")
    error: Optional[str] = Field(default=None, description="Error message if failed")
    retry_count: int = Field(default=0, description="Number of retries attempted")
    items_extracted: int = Field(default=0, description="Number of items extracted")
```

Update BuildingSpec to include extraction metadata:

```python
class BuildingSpec(BaseModel):
    """Complete building specification from extraction."""
    # ... existing fields ...

    # Extraction metadata (add at end)
    extraction_status: Dict[str, ExtractionStatus] = Field(default_factory=dict, description="Per-domain extraction status")
    conflicts: List[ExtractionConflict] = Field(default_factory=list, description="Conflicts between extractors")
```

Also add the necessary imports at the top:
```python
from typing import Optional, List, Dict, Any
```
  </action>
  <verify>
    - python -c "from schemas.building_spec import ExtractionConflict, ExtractionStatus; print('OK')"
    - python -c "from schemas.building_spec import BuildingSpec; b = BuildingSpec(); print(b.extraction_status, b.conflicts)"
    - grep "ExtractionConflict" src/schemas/building_spec.py
    - grep "extraction_status" src/schemas/building_spec.py
  </verify>
  <done>
    BuildingSpec schema extended with ExtractionConflict, ExtractionStatus models and corresponding fields for tracking extraction metadata.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Parallel Extraction with Merge Logic</name>
  <files>src/agents/orchestrator.py</files>
  <action>
Extend orchestrator.py to support parallel multi-domain extraction. Key additions:

**1. Add asyncio imports and semaphore:**
```python
import asyncio
from typing import Tuple

EXTRACTION_SEMAPHORE = asyncio.Semaphore(3)  # Max 3 concurrent extractors
```

**2. Add async agent invocation wrapper:**
```python
async def invoke_claude_agent_async(agent_name: str, prompt: str, timeout: int = 600) -> str:
    """Async wrapper for Claude Code agent invocation."""
    async with EXTRACTION_SEMAPHORE:
        return await asyncio.to_thread(
            invoke_claude_agent,
            agent_name,
            prompt,
            timeout
        )
```

**3. Add extraction with retry function:**
```python
async def extract_with_retry(
    agent_name: str,
    prompt: str,
    timeout: int = 600
) -> Tuple[Optional[Dict[str, Any]], ExtractionStatus]:
    """
    Extract with one retry on failure.
    Returns (data, status) tuple.
    """
    domain = agent_name.replace("-extractor", "")

    for attempt in range(2):
        try:
            response = await invoke_claude_agent_async(agent_name, prompt, timeout)
            data = extract_json_from_response(response)

            # Count items extracted
            items = 0
            for key, val in data.items():
                if isinstance(val, list):
                    items += len(val)

            return data, ExtractionStatus(
                domain=domain,
                status="success",
                retry_count=attempt,
                items_extracted=items
            )
        except Exception as e:
            if attempt == 0:
                logger.warning(f"{agent_name} attempt 1 failed: {e}, retrying...")
                await asyncio.sleep(2)
            else:
                logger.error(f"{agent_name} failed after retry: {e}")
                return None, ExtractionStatus(
                    domain=domain,
                    status="failed",
                    error=str(e),
                    retry_count=1
                )

    return None, ExtractionStatus(domain=domain, status="failed", error="Unknown")
```

**4. Add parallel extraction function:**
```python
async def run_parallel_extraction(
    page_images: List[Path],
    document_map: DocumentMap
) -> Dict[str, Tuple[Optional[Dict], ExtractionStatus]]:
    """Run all domain extractors in parallel."""
    # Build prompts for each domain
    zones_prompt = build_domain_prompt("zones", page_images, document_map)
    windows_prompt = build_domain_prompt("windows", page_images, document_map)
    hvac_prompt = build_domain_prompt("hvac", page_images, document_map)
    dhw_prompt = build_domain_prompt("dhw", page_images, document_map)

    # Create extraction tasks
    tasks = [
        extract_with_retry("zones-extractor", zones_prompt),
        extract_with_retry("windows-extractor", windows_prompt),
        extract_with_retry("hvac-extractor", hvac_prompt),
        extract_with_retry("dhw-extractor", dhw_prompt),
    ]

    # Run in parallel
    results = await asyncio.gather(*tasks)

    return {
        "zones": results[0],
        "windows": results[1],
        "hvac": results[2],
        "dhw": results[3],
    }
```

**5. Add prompt builder:**
```python
def build_domain_prompt(domain: str, page_images: List[Path], document_map: DocumentMap) -> str:
    """Build extraction prompt for a specific domain."""
    # Filter to relevant pages (schedule + CBECC for all domains)
    relevant_pages = sorted(set(document_map.schedule_pages + document_map.cbecc_pages))

    # Windows also benefit from drawing pages (floor plans show window locations)
    if domain == "windows":
        relevant_pages = sorted(set(relevant_pages + document_map.drawing_pages[:5]))

    page_list = "\n".join([
        f"- Page {p}: {page_images[p-1]}"
        for p in relevant_pages
        if p <= len(page_images)
    ])

    document_map_json = json.dumps(document_map.model_dump(), indent=2)

    return f"""Extract {domain} data from this Title 24 document.

Document structure (from discovery):
{document_map_json}

Relevant page image paths:
{page_list}

Read your instructions from:
- .claude/instructions/{domain}-extractor/instructions.md
- .claude/instructions/{domain}-extractor/field-guide.md

Return JSON matching the schema for {domain} extraction.
Focus on accuracy and completeness.
"""
```

**6. Add name-based deduplication:**
```python
def deduplicate_by_name(items: List[BaseModel], source: str) -> Tuple[List[BaseModel], List[ExtractionConflict]]:
    """Deduplicate items by name, tracking conflicts."""
    seen: Dict[str, BaseModel] = {}
    conflicts = []

    for item in items:
        name = getattr(item, 'name', None)
        if name is None:
            continue

        if name in seen:
            existing = seen[name]
            # Check if values differ
            if item.model_dump() != existing.model_dump():
                conflicts.append(ExtractionConflict(
                    field="array_item",
                    item_name=name,
                    source_extractor=source,
                    reported_value=existing.model_dump(),
                    conflicting_extractor=source,
                    conflicting_value=item.model_dump(),
                    resolution="kept_first"
                ))
        else:
            seen[name] = item

    return list(seen.values()), conflicts
```

**7. Add merge function:**
```python
def merge_extractions(
    project_data: Dict[str, Any],
    domain_extractions: Dict[str, Tuple[Optional[Dict], ExtractionStatus]]
) -> Tuple[BuildingSpec, List[ExtractionConflict], Dict[str, ExtractionStatus]]:
    """Merge all extractions into BuildingSpec."""
    conflicts = []
    extraction_status = {"project": ExtractionStatus(domain="project", status="success", items_extracted=2)}

    # Start with project extraction
    spec = BuildingSpec(
        project=ProjectInfo.model_validate(project_data["project"]),
        envelope=EnvelopeInfo.model_validate(project_data["envelope"])
    )

    # Merge zones
    zones_data, zones_status = domain_extractions["zones"]
    extraction_status["zones"] = zones_status
    if zones_data:
        if "zones" in zones_data:
            zones = [ZoneInfo.model_validate(z) for z in zones_data["zones"]]
            spec.zones, zone_conflicts = deduplicate_by_name(zones, "zones")
            conflicts.extend(zone_conflicts)
        if "walls" in zones_data:
            walls = [WallComponent.model_validate(w) for w in zones_data["walls"]]
            spec.walls, wall_conflicts = deduplicate_by_name(walls, "zones")
            conflicts.extend(wall_conflicts)

    # Merge windows
    windows_data, windows_status = domain_extractions["windows"]
    extraction_status["windows"] = windows_status
    if windows_data and "windows" in windows_data:
        windows = [WindowComponent.model_validate(w) for w in windows_data["windows"]]
        spec.windows, window_conflicts = deduplicate_by_name(windows, "windows")
        conflicts.extend(window_conflicts)

    # Merge HVAC
    hvac_data, hvac_status = domain_extractions["hvac"]
    extraction_status["hvac"] = hvac_status
    if hvac_data and "hvac_systems" in hvac_data:
        systems = [HVACSystem.model_validate(s) for s in hvac_data["hvac_systems"]]
        spec.hvac_systems, hvac_conflicts = deduplicate_by_name(systems, "hvac")
        conflicts.extend(hvac_conflicts)

    # Merge DHW
    dhw_data, dhw_status = domain_extractions["dhw"]
    extraction_status["dhw"] = dhw_status
    if dhw_data and "water_heating_systems" in dhw_data:
        wh_systems = [WaterHeatingSystem.model_validate(s) for s in dhw_data["water_heating_systems"]]
        spec.water_heating_systems, dhw_conflicts = deduplicate_by_name(wh_systems, "dhw")
        conflicts.extend(dhw_conflicts)

    return spec, conflicts, extraction_status
```

**8. Update run_extraction to use parallel extraction:**
Update the existing `run_extraction` function to:
1. Call run_discovery (unchanged)
2. Call run_project_extraction (unchanged)
3. Call asyncio.run(run_parallel_extraction(...))
4. Call merge_extractions to combine all results
5. Add extraction_status and conflicts to BuildingSpec
6. Return complete result

Add necessary imports at top:
```python
from schemas.building_spec import (
    BuildingSpec, ProjectInfo, EnvelopeInfo, ZoneInfo, WallComponent,
    WindowComponent, HVACSystem, WaterHeatingSystem,
    ExtractionConflict, ExtractionStatus
)
```
  </action>
  <verify>
    - python -c "from agents.orchestrator import run_parallel_extraction; print('OK')"
    - python -c "from agents.orchestrator import merge_extractions; print('OK')"
    - grep "asyncio.gather" src/agents/orchestrator.py
    - grep "zones-extractor" src/agents/orchestrator.py
    - grep "windows-extractor" src/agents/orchestrator.py
    - grep "hvac-extractor" src/agents/orchestrator.py
    - grep "dhw-extractor" src/agents/orchestrator.py
    - grep "ExtractionConflict" src/agents/orchestrator.py
    - wc -l src/agents/orchestrator.py (>400 lines expected)
  </verify>
  <done>
    Orchestrator extended with asyncio-based parallel extraction for all 4 domain extractors. Merge logic deduplicates by name and flags conflicts. Extraction status tracked per domain. Partial failures handled gracefully.
  </done>
</task>

</tasks>

<verification>
After both tasks complete:

1. Schema has new models:
   - python -c "from schemas.building_spec import ExtractionConflict, ExtractionStatus, BuildingSpec; print('OK')"

2. Orchestrator has parallel extraction:
   - grep "asyncio" src/agents/orchestrator.py shows imports and usage
   - All 4 extractors referenced: zones, windows, hvac, dhw

3. Module imports work:
   - python -c "from agents.orchestrator import run_extraction; print('OK')"

4. Code structure:
   - wc -l src/agents/orchestrator.py shows >400 lines (significant expansion)
</verification>

<success_criteria>
- Parallel extraction uses asyncio.gather with 3-concurrent semaphore
- All 4 domain extractors invoked (zones, windows, hvac, dhw)
- Merge logic handles all domain outputs
- Conflicts detected and flagged (not auto-resolved per CONTEXT.md decision)
- Extraction status tracked per domain
- Partial failures don't crash entire extraction
- BuildingSpec includes extraction_status and conflicts fields
</success_criteria>

<output>
After completion, create `.planning/phases/04-multi-domain-extraction/04-03-SUMMARY.md`
</output>
